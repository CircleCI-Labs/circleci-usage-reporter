{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# CircleCI Job Analysis Report\n",
    "\n",
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and configuration\n",
    "import analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Initialize the analysis environment\n",
    "helpers = analysis.initialize_notebook()\n",
    "pp = helpers['pp']\n",
    "summarize_dataset = helpers['summarize_dataset']\n",
    "\n",
    "# Configuration - can be set via environment variables or modified directly\n",
    "filepath = os.getenv(\"FILEPATH\", \"/tmp/merged.csv\")\n",
    "project_name = os.getenv(\"PROJECT_NAME\", \"my-project\") \n",
    "individual_job_name = os.getenv(\"JOB_NAME\", \"deploy\")\n",
    "credit_cost = float(os.getenv(\"CREDIT_COST\", \"0.0006\"))\n",
    "\n",
    "# Load data to get organization name for report header\n",
    "temp_df = pd.read_csv(filepath, escapechar=\"\\\\\", na_values=[\"\\\\N\"], nrows=1)\n",
    "org_name = temp_df['ORGANIZATION_NAME'].iloc[0] if 'ORGANIZATION_NAME' in temp_df.columns else \"Unknown Organization\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CircleCI Job Analysis Report\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Organization: {org_name}\")\n",
    "print(f\"Project: {project_name}\")\n",
    "print(f\"Job: {individual_job_name}\")\n",
    "print(f\"Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  File: {filepath}\")\n",
    "print(f\"  Credit Cost: {credit_cost}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data using the analysis library\n",
    "df, project_dfs = analysis.load_circleci_data(\n",
    "    filepath=filepath,\n",
    "    project_name=project_name,\n",
    "    credit_cost=credit_cost\n",
    ")\n",
    "\n",
    "# Extract project-specific datasets\n",
    "all_jobs = project_dfs['all_jobs']\n",
    "ps_jobs = project_dfs['ps_jobs']\n",
    "ps_master_jobs = project_dfs['ps_master_jobs']\n",
    "ps_pr_jobs = project_dfs['ps_pr_jobs']\n",
    "ps_pr_passed_jobs = project_dfs['ps_pr_passed_jobs']\n",
    "ps_pr_failed_jobs = project_dfs['ps_pr_failed_jobs']\n",
    "\n",
    "# Print dataset summaries\n",
    "print(\"Dataset Summary:\")\n",
    "print(summarize_dataset(all_jobs, \"All jobs\"))\n",
    "print(summarize_dataset(ps_jobs, \"Project-specific jobs\"))\n",
    "print(summarize_dataset(ps_master_jobs, \"Master branch jobs\"))\n",
    "print(summarize_dataset(ps_pr_jobs, \"PR branch jobs\"))\n",
    "print(summarize_dataset(ps_pr_passed_jobs, \"Passed PR jobs\"))\n",
    "print(summarize_dataset(ps_pr_failed_jobs, \"Failed PR jobs\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 Jobs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 jobs by longest average duration\n",
    "job_duration_stats = ps_jobs.groupby(\"JOB_NAME\").agg({\n",
    "    \"JOB_RUN_SECONDS\": [\"mean\", \"median\", \"count\"],\n",
    "    \"COST\": [\"sum\", \"mean\"]\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "job_duration_stats.columns = [\"_\".join(col).strip() for col in job_duration_stats.columns]\n",
    "job_duration_stats = job_duration_stats.reset_index()\n",
    "\n",
    "# Filter jobs with at least 5 runs for statistical significance\n",
    "job_duration_stats = job_duration_stats[job_duration_stats[\"JOB_RUN_SECONDS_count\"] >= 5]\n",
    "\n",
    "# Convert duration to minutes for readability\n",
    "job_duration_stats[\"AVG_DURATION_MINUTES\"] = job_duration_stats[\"JOB_RUN_SECONDS_mean\"] / 60\n",
    "job_duration_stats[\"MEDIAN_DURATION_MINUTES\"] = job_duration_stats[\"JOB_RUN_SECONDS_median\"] / 60\n",
    "\n",
    "# Top 10 by average duration\n",
    "top_duration_jobs = job_duration_stats.sort_values(\"JOB_RUN_SECONDS_mean\", ascending=False).head(10)\n",
    "pp(top_duration_jobs[[\n",
    "    \"JOB_NAME\", \n",
    "    \"AVG_DURATION_MINUTES\", \n",
    "    \"MEDIAN_DURATION_MINUTES\", \n",
    "    \"JOB_RUN_SECONDS_count\", \n",
    "    \"COST_sum\",\n",
    "    \"COST_mean\"\n",
    "]], \"Top 10 Jobs by Longest Average Duration (minutes)\")\n",
    "\n",
    "if len(top_duration_jobs) > 0:\n",
    "    min_duration = top_duration_jobs['AVG_DURATION_MINUTES'].min()\n",
    "    print(f\"\\nüìä Summary: Top {len(top_duration_jobs)} jobs by duration (minimum: {min_duration:.1f} minutes)\")\n",
    "    print(f\"üí∞ Combined cost of these top {len(top_duration_jobs)} slowest job types: ${top_duration_jobs['COST_sum'].sum():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 jobs by total cost\n",
    "top_cost_jobs = job_duration_stats.sort_values(\"COST_sum\", ascending=False).head(10)\n",
    "pp(top_cost_jobs[[\n",
    "    \"JOB_NAME\", \n",
    "    \"COST_sum\",\n",
    "    \"COST_mean\",\n",
    "    \"JOB_RUN_SECONDS_count\", \n",
    "    \"AVG_DURATION_MINUTES\", \n",
    "    \"MEDIAN_DURATION_MINUTES\"\n",
    "]], \"Top 10 Jobs by Highest Total Cost\")\n",
    "\n",
    "print(f\"\\nüí∞ Combined cost of these top 10 most expensive job types: ${top_cost_jobs['COST_sum'].sum():.2f}\")\n",
    "print(f\"üìä These jobs represent {(top_cost_jobs['COST_sum'].sum() / ps_jobs['COST'].sum() * 100):.1f}% of total project cost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Individual Job Analysis\n",
    "\n",
    "Analysis of the most expensive and slowest individual job runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most expensive individual jobs\n",
    "expensive_jobs = ps_jobs.sort_values(\"COST\", ascending=False)\n",
    "pp(expensive_jobs[[\"JOB_NAME\", \"JOB_RUN_DATE\", \"VCS_BRANCH\", \"COST\", \"DURATION\", \"COMPUTE_CREDITS\", \"JOB_URL\"]].head(), \n",
    "   \"Most Expensive Individual Jobs\")\n",
    "\n",
    "# Slowest individual jobs\n",
    "slow_jobs = ps_jobs.sort_values(\"JOB_RUN_SECONDS\", ascending=False)\n",
    "pp(slow_jobs[[\"JOB_ID\", \"JOB_NAME\", \"JOB_RUN_DATE\", \"VCS_BRANCH\", \"COST\", \"DURATION\", \"JOB_URL\"]].head(),\n",
    "   \"Slowest Individual Jobs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Pipeline Analysis\n",
    "\n",
    "### Analysis of pipeline costs, frequency, and branch patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline cost distribution for PR branches\n",
    "pr_pipeline_costs = ps_pr_jobs.groupby(\"PIPELINE_ID\").agg(\n",
    "    COST=(\"COST\", \"sum\"), \n",
    "    NUM_FAILS=('JOB_BUILD_STATUS', lambda x: (x != 'success').sum())\n",
    ").reset_index()\n",
    "\n",
    "analysis.plot_cost_distribution(\n",
    "    pr_pipeline_costs[\"COST\"],\n",
    "    title=\"Pipeline cost distribution for PR branches\",  \n",
    "    bins=60\n",
    ")\n",
    "\n",
    "print(\"PR Pipeline Cost Statistics:\")\n",
    "print(pr_pipeline_costs.describe())\n",
    "\n",
    "# Pipeline cost distribution for master branch\n",
    "master_pipeline_costs = ps_master_jobs.groupby(\"PIPELINE_ID\").agg({\"COST\": \"sum\"}).reset_index()\n",
    "analysis.plot_cost_distribution(\n",
    "    master_pipeline_costs[\"COST\"],\n",
    "    title=\"Pipeline cost distribution for master branch\",  \n",
    "    bins=60\n",
    ")\n",
    "\n",
    "print(\"\\nMaster Pipeline Cost Statistics:\")\n",
    "print(master_pipeline_costs.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Specific Job Analysis\n",
    "\n",
    "### Detailed analysis of a specific job type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of specific job\n",
    "job_pattern = individual_job_name\n",
    "_df = ps_jobs\n",
    "\n",
    "# Check available jobs\n",
    "available_jobs = _df[\"JOB_NAME\"].dropna().unique()\n",
    "print(f\"Available jobs: {list(available_jobs[:10])}...\")  # Show first 10\n",
    "\n",
    "# Filter to specific job\n",
    "filtered_jobs = _df[_df[\"JOB_NAME\"] == job_pattern]\n",
    "df_description = f\"`{job_pattern}` across all pipelines\"\n",
    "\n",
    "if filtered_jobs.empty:\n",
    "    print(f\"‚ö†Ô∏è  No data found for job '{job_pattern}'. Available jobs: {list(available_jobs[:5])}\")\n",
    "    print(\"Consider updating the individual_job_name parameter to one of the available jobs.\")\n",
    "else:\n",
    "    print(f\"Found {len(filtered_jobs)} instances of job '{job_pattern}'\")\n",
    "    \n",
    "    # Duration analysis\n",
    "    analysis.analyse_durations(\n",
    "        filtered_jobs[\"JOB_RUN_SECONDS\"],\n",
    "        title=f\"{df_description} duration distribution\",\n",
    "        max_xvalue=30*60,\n",
    "        bins=20,\n",
    "    )\n",
    "    \n",
    "    # Cost distribution\n",
    "    analysis.plot_cost_distribution(\n",
    "        filtered_jobs[\"COST\"],\n",
    "        title=f\"{df_description} cost distribution\",\n",
    "        bins=20,\n",
    "    )\n",
    "    \n",
    "    # Show slowest instances\n",
    "    _sorted = filtered_jobs.sort_values(\"JOB_RUN_SECONDS\", ascending=False)\n",
    "    pp(_sorted[[\"WORKFLOW_ID\", \"DURATION\", \"COST\", \"VCS_BRANCH\", \"JOB_URL\"]].head(10),\n",
    "       f\"Slowest instances of {job_pattern}\")\n",
    "    \n",
    "    # Show most expensive instances\n",
    "    _sorted = filtered_jobs.sort_values(\"COST\", ascending=False)\n",
    "    pp(_sorted[[\"WORKFLOW_ID\", \"JOB_RUN_SECONDS\", \"COST\", \"JOB_URL\"]].head(10),\n",
    "       f\"Most expensive instances of {job_pattern}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
